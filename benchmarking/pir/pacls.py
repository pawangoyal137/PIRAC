import pandas as pd
import json
import argparse
import math
import numpy as np
import subprocess
import os

from pirac import cal_pirac_tput

import utils

SCHEMES = ["xor", "pir", "pir_keyword", "pir_pacl", "pir_keyword_baseline"]
JSON_PATH = f'{utils.PACLsPath}/pir.json'

# define the parser for running the experiments
parser = argparse.ArgumentParser(description='Run benchmarking for PACLs')
parser.add_argument('-o', '--output', action='store_true',
                    required=False,
                    help='If the flag is passed, display the output of the PACLs')
parser.add_argument('-w', '--writeFile',
                    required=False, type=str,
                    default="results/data/multi_server/multi_server.json",
                    help='Tells where to write the results')

pd.set_option('display.max_columns', None)

def process_pacls_results(write_file, output=False):
    # Read the JSON file
    with open(JSON_PATH) as f:
        data = json.load(f)

    # Create a list of dictionaries with the desired columns
    processed_data = []
    pirac_tput_results = {}
    pir_tputs_std = {}
    for d in data:
        db_size_bytes = d["db_size"]*d["item_size"]
        row = {
            'log2_db_size': d['db_size'],
            'elem_size': d['item_size']
        }
        for s in SCHEMES:
            row[f"{s}_us"] = np.mean(d[f'server_{s}_processing_ms'])
            row[f"{s}_tput"] = db_size_bytes / (row[f"{s}_us"])
            row[f"{s}_tput_std_pct"] = 100 * \
                np.std(d[f'server_{s}_processing_ms']) / \
                np.mean(d[f'server_{s}_processing_ms'])

            pir_tputs_std[f"{s}_tput_std"] = row[f"{s}_tput"]*np.std(
                d[f'server_{s}_processing_ms'])/np.mean(d[f'server_{s}_processing_ms'])

        db_size_log2 = int(math.log2(d["db_size"]))
        elem_size_bits = 8*d["item_size"]

        if (db_size_log2, elem_size_bits) not in pirac_tput_results:
            pirac_tput_results[(db_size_log2, elem_size_bits)] = cal_pirac_tput(db_size_log2,
                                                                                elem_size_bits, 5, key_refresh=True, output=True)
        pirac_tput, pirac_tput_std = pirac_tput_results[(
            db_size_log2, elem_size_bits)]
        row["xor_pirac_tput"] = utils.cal_tput_with_pirac(
            row["xor_tput"], pirac_tput)
        row["pir_pirac_tput"] = utils.cal_tput_with_pirac(
            row["pir_tput"], pirac_tput)

        row["xor_pirac_tput_std_pct"] = (100*row["xor_pirac_tput"] *
                                         (pirac_tput_std/np.square(pirac_tput)+pir_tputs_std["xor_tput_std"]/np.square(row["xor_tput"])))
        row["pir_pirac_tput_std_pct"] = (100*row["pir_pirac_tput"] *
                                         (pirac_tput_std/np.square(pirac_tput)+pir_tputs_std["pir_tput_std"]/np.square(row["pir_tput"])))
        processed_data.append(row)

    with open(write_file, "w") as f:
        json.dump(processed_data, f, separators=(",\n", ": "))

    if output:
        # Create a pandas DataFrame from the list of dictionaries
        df = pd.DataFrame(processed_data)

        # Set the db_size column as the index of the DataFrame
        df = df.set_index('elem_size')

        # Sort the DataFrame by db_size and item_size in ascending order
        df = df.sort_values(['log2_db_size', 'elem_size'],
                            ascending=[True, True])

        # Print the sorted DataFrame
        print(df)

    return processed_data

def run_pacls(write_file, output=False):
    cwd = os.getcwd()
    os.chdir(utils.PACLsPath)

    # remove any old results
    if os.path.isfile("pir.json"):
        os.remove("pir.json")

    process = subprocess.Popen(f"bash run.sh",
                                shell=True,
                                stdout=subprocess.PIPE,
                                stderr=subprocess.PIPE,
                                universal_newlines=True)

    while True:
        line = process.stdout.readline()

        if output:
            print(line.rstrip())

        return_code = process.poll()
        if return_code is not None:
            break
    os.chdir(cwd)

    # process the results generated by PACLs code
    process_pacls_results(write_file, output)
    return 

if __name__ == "__main__":
    args = parser.parse_args()
    output = args.output
    write_file = args.writeFile

    run_pacls(write_file, output)
